{"cells":[{"cell_type":"markdown","source":["# Environment setup - Vertex AI Colab"],"metadata":{"id":"WIfWqodThshR"}},{"cell_type":"code","source":["!python -m pip install transformers accelerate bitsandbytes\n","!python -m pip install peft\n","!python -m pip install datasets\n","!python -m pip install sentencepiece scipy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFQLAk3XxUpC","executionInfo":{"status":"ok","timestamp":1701650814349,"user_tz":300,"elapsed":35303,"user":{"displayName":"Hernan Figueroa","userId":"13184450879028133407"}},"outputId":"6a6dfff5-69d1-4f54-82f4-aa60352c7fb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Collecting accelerate\n","  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bitsandbytes\n","  Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: bitsandbytes, accelerate\n","Successfully installed accelerate-0.25.0 bitsandbytes-0.41.2.post2\n","Collecting peft\n","  Downloading peft-0.6.2-py3-none-any.whl (174 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu118)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.35.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.25.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->peft) (0.19.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Installing collected packages: peft\n","Successfully installed peft-0.6.2\n","Collecting datasets\n","  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting pyarrow-hotfix (from datasets)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n","Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"markdown","source":["## Check environment"],"metadata":{"id":"JXboMu9GnfQD"}},{"cell_type":"code","source":["import torch\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rOkQnvzQuRV9","executionInfo":{"status":"ok","timestamp":1701650818108,"user_tz":300,"elapsed":3763,"user":{"displayName":"Hernan Figueroa","userId":"13184450879028133407"}},"outputId":"2053c144-e97e-40c5-8fd6-453d70241610"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.1.0+cu118\n"]}]},{"cell_type":"code","source":["!nvidia-smi --query-gpu=timestamp,memory.total,memory.used,memory.free --format=csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yhgB9mptuXja","executionInfo":{"status":"ok","timestamp":1701650818109,"user_tz":300,"elapsed":25,"user":{"displayName":"Hernan Figueroa","userId":"13184450879028133407"}},"outputId":"df13bc59-364d-45d4-ec6c-8bf50c78647e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["timestamp, memory.total [MiB], memory.used [MiB], memory.free [MiB]\n","2023/12/04 00:46:56.370, 15360 MiB, 0 MiB, 15101 MiB\n"]}]},{"cell_type":"markdown","metadata":{"id":"35Dvbzb0hH3-"},"source":["## Import necessary packages"]},{"cell_type":"code","source":["import json\n","import os\n","import gc\n","\n","import sys\n","from datasets import load_dataset\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from transformers import LlamaForCausalLM, LlamaTokenizer, LlamaConfig"],"metadata":{"id":"2rlCosp__8pH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding"],"metadata":{"id":"F8U94O3OofsH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Login into Google cloud storage to get models"],"metadata":{"id":"D_ZLqptUVOvz"}},{"cell_type":"code","source":["# Cloud project id.\n","PROJECT_ID = \"capstone-engie4800\"  # @param {type:\"string\"}\n","REGION = \"us-central1\"  # @param {type:\"string\"}\n","# Cloud Storage bucket for storing experiments output.\n","BUCKET_URI = \"gs://vertex-xt72os9\"  # @param {type:\"string\"}\n","!gcloud auth login\n","!gcloud config set project $PROJECT_ID"],"metadata":{"id":"kvAxMUzkVOYG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701650844902,"user_tz":300,"elapsed":23525,"user":{"displayName":"Hernan Figueroa","userId":"13184450879028133407"}},"outputId":"196a5409-8852-4a7f-abcb-2b0cda76576b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","You are running on a Google Compute Engine virtual machine.\n","It is recommended that you use service accounts for authentication.\n","\n","You can run:\n","\n","  $ gcloud config set account `ACCOUNT`\n","\n","to switch accounts if necessary.\n","\n","Your credentials may be visible to others with access to this\n","virtual machine. Are you sure you want to authenticate with\n","your personal account?\n","\n","Do you want to continue (Y/n)?  Y\n","\n","Go to the following link in your browser:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=D9LJHm8AvdQRRR1VNsVzPvypldOYb8&prompt=consent&access_type=offline&code_challenge=8eJ7NT55xo7HdFOJlCgoRfdW02ooidgLeNplyUtDbWQ&code_challenge_method=S256\n","\n","Enter authorization code: 4/0AfJohXnugHjVbt0TMgsrQwzaQ7NSbA2eB5Tzc7GqHj0cBUgJhiwUnoC9uCQUBhvPj7IkLw\n","\n","You are now logged in as [hf2314@columbia.edu].\n","Your current project is [None].  You can change this setting by running:\n","  $ gcloud config set project PROJECT_ID\n","Updated property [core/project].\n"]}]},{"cell_type":"markdown","source":["## Copy models from Cloud Storage\n","The base model used was llama2-7b-chat-hf"],"metadata":{"id":"T_IrVEyPvoq9"}},{"cell_type":"code","source":["base_model_name = \"llama2-7b-chat-hf\"  # @param [\"llama2-7b-hf\", \"llama2-7b-chat-hf\", \"llama2-13b-hf\", \"llama2-13b-chat-hf\", \"llama2-70b-hf\", \"llama2-70b-chat-hf\"]\n","\n","BPO_MODEL_PATH = os.path.join(BUCKET_URI,\n","                              \"peft\",\n","                              \"BPO_model\",\n","                              \"BPO_models\")"],"metadata":{"id":"BTfNlL9CVndG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2MjaORIIFDVu"},"source":["Uncoment the copy command below to copy the model from the bucket to BPO_model"]},{"cell_type":"code","source":["local_model_folder = \"/content/\"\n","!gsutil -m cp -R $BPO_MODEL_PATH/BPO_model $local_model_folder"],"metadata":{"id":"VWGwheOIXOeo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701652036589,"user_tz":300,"elapsed":1191694,"user":{"displayName":"Hernan Figueroa","userId":"13184450879028133407"}},"outputId":"97b799cb-3244-4261-8832-b079f2175835"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/BPO_model/pytorch_model-00001-of-00002.bin...\n","/ [0/7 files][    0.0 B/ 12.6 GiB]   0% Done                                    \rCopying gs://vertex-xt72os9/peft/BPO_model/BPO_models/BPO_model/config.json...\n","/ [0/7 files][    0.0 B/ 12.6 GiB]   0% Done                                    \r==> NOTE: You are downloading one or more large file(s), which would\n","run significantly faster if you enabled sliced object downloads. This\n","feature is enabled by default but requires that compiled crcmod be\n","installed (see \"gsutil help crcmod\").\n","\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/BPO_model/tokenizer.model...\n","/ [0/7 files][    0.0 B/ 12.6 GiB]   0% Done                                    \rCopying gs://vertex-xt72os9/peft/BPO_model/BPO_models/BPO_model/pytorch_model-00002-of-00002.bin...\n","/ [0/7 files][    0.0 B/ 12.6 GiB]   0% Done                                    \rCopying gs://vertex-xt72os9/peft/BPO_model/BPO_models/BPO_model/pytorch_model.bin.index.json...\n","/ [0/7 files][    0.0 B/ 12.6 GiB]   0% Done                                    \rCopying gs://vertex-xt72os9/peft/BPO_model/BPO_models/BPO_model/tokenizer_config.json...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/BPO_model/special_tokens_map.json...\n","/ [7/7 files][ 12.6 GiB/ 12.6 GiB] 100% Done  16.7 MiB/s ETA 00:00:00           \n","Operation completed over 7 objects/12.6 GiB.                                     \n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/USE_POLICY.md...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/LICENSE...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/config.json...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/MODEL_CARD.md...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/LLaMA V2 Model Preview User Guide.pdf...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/config.json.bak...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/Notice-File.docx...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/Responsible-Use-Guide.pdf...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/generation_config.json...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/pytorch_model-00001-of-00002.bin...\n","==> NOTE: You are downloading one or more large file(s), which would\n","run significantly faster if you enabled sliced object downloads. This\n","feature is enabled by default but requires that compiled crcmod be\n","installed (see \"gsutil help crcmod\").\n","\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/pytorch_model-00002-of-00002.bin...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/pytorch_model.bin.index.json...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/special_tokens_map.json...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/tokenizer.json...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/tokenizer.model...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/llama2-7b-chat-hf/tokenizer_config.json...\n","\\ [16/16 files][ 12.6 GiB/ 12.6 GiB] 100% Done  16.1 MiB/s ETA 00:00:00         \n","Operation completed over 16 objects/12.6 GiB.                                    \n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/capstone_peft_adapter/README.md...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/capstone_peft_adapter/adapter_config.json...\n","Copying gs://vertex-xt72os9/peft/BPO_model/BPO_models/capstone_peft_adapter/adapter_model.bin...\n","/ [3/3 files][ 16.0 MiB/ 16.0 MiB] 100% Done                                    \n","Operation completed over 3 objects/16.0 MiB.                                     \n"]}]},{"cell_type":"markdown","source":["# LOADING MODEL\n","In Colab Enterprise using L4 GPU with 24G of RAM\n","\n","In Colab Free using T4 with 14G of RAM"],"metadata":{"id":"83_ZXnNitzrA"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","precision_loading_mode = \"float16\""],"metadata":{"id":"_t_StyFyCP3F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load BPO paper model"],"metadata":{"id":"PNEh7MdUeyck"}},{"cell_type":"code","source":["bpo_model_id = 'BPO_model'\n","bpo_model_path = os.path.join(local_model_folder,\n","                              bpo_model_id)\n","bpo_model = AutoModelForCausalLM.from_pretrained(bpo_model_path,\n","                                             load_in_8bit=True,\n","                                             device_map=\"auto\",\n","                                             torch_dtype=torch.float16,\n","                                             use_cache=None)\n","tokenizer = AutoTokenizer.from_pretrained(bpo_model_path,\n","                                           device_map=\"auto\",\n","                                           torch_dtype=torch.float16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77,"referenced_widgets":["73ce83ca131e4d63a17e92dab22ce4b9","f1f086f6816c4702a3a781427c68fde3","0b94b81d4a2a4556ab7e6ebbeae001ea","d16fd7abf5494cffba620cc665e1a5f5","cd2b6d75c1da467d930f24925f393051","c6febc3d5969403f8e2453e494c0f733","8a08515ef7a44e1a894ac4cd01cfc312","801c94bee36544ca8d2e0d37553209d2","917c63ab4c1b4570805360e6b443b811","880c31218c0e4f62a740f2821557b717","646853db92ad414eb268a61f57b1d373"]},"id":"ZewpBQi9elqN","executionInfo":{"status":"ok","timestamp":1701652118719,"user_tz":300,"elapsed":82135,"user":{"displayName":"Hernan Figueroa","userId":"13184450879028133407"}},"outputId":"75bec54d-c2a5-459b-b65a-6b8489d6dc64"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73ce83ca131e4d63a17e92dab22ce4b9"}},"metadata":{}}]},{"cell_type":"code","source":["prompt_template = \"[INST] You are an expert prompt engineer. Please help me improve this prompt to get a more helpful response:\\n{} [/INST]\"\n","text = 'What is the best company stock to invest my savings?'\n","prompt = prompt_template.format(text)\n","model_inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)"],"metadata":{"id":"S6SECFajLsBu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output = bpo_model.generate(**model_inputs, max_new_tokens=1024, do_sample=True, top_p=0.9, temperature=0.05, num_beams=1)\n","resp = tokenizer.decode(output[0], skip_special_tokens=True).split('[/INST]')[1].strip()\n","\n","print(resp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c356hG_8CG8F","executionInfo":{"status":"ok","timestamp":1701652135868,"user_tz":300,"elapsed":16484,"user":{"displayName":"Hernan Figueroa","userId":"13184450879028133407"}},"outputId":"70d33318-443c-40ce-f75c-8b80f871d0cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["What factors should I consider when choosing a company stock to invest my savings in?\n"]}]},{"cell_type":"code","source":["assert False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"Ua8lVL0hSU9K","executionInfo":{"status":"error","timestamp":1701652135869,"user_tz":300,"elapsed":23,"user":{"displayName":"Hernan Figueroa","userId":"13184450879028133407"}},"outputId":"78ddaa0e-c5c5-4a92-ea8f-69e8b83e7295"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-a871fdc9ebee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAssertionError\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Loading Base model"],"metadata":{"id":"DE4jdb0qJn4B"}},{"cell_type":"markdown","source":["To load the base model in Colab free we have to clear the BPO model.\n","In Colab Enterprise, we can load both models at the same time"],"metadata":{"id":"joyMtzM-MujK"}},{"cell_type":"code","source":["#del base_model\n","#del tokenizer\n","#gc.collect()\n","#torch.cuda.empty_cache()"],"metadata":{"id":"hA0BktDeMFj9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!gsutil -m cp -R $BPO_MODEL_PATH/llama2-7b-chat-hf $local_model_folder\n","#!gsutil -m cp -R $BPO_MODEL_PATH/capstone_peft_adapter $local_model_folder"],"metadata":{"id":"E9bG_GUwU4Ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model_name = \"llama2-7b-chat-hf\"\n","model_path = os.path.join(local_model_folder,\n","                          base_model_name)\n","base_model = LlamaForCausalLM.from_pretrained(model_path,\n","                                              load_in_8bit=True,\n","                                              device_map=\"auto\",\n","                                              torch_dtype=torch.float16,\n","                                              use_cache=None)\n","tokenizer = LlamaTokenizer.from_pretrained(model_path,\n","                                           device_map=\"auto\",\n","                                           torch_dtype=torch.float16)\n","tokenizer.pad_token_id = tokenizer.eos_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"OMIlBYPJxx84","executionInfo":{"status":"error","timestamp":1701652768995,"user_tz":300,"elapsed":14,"user":{"displayName":"Hernan Figueroa","userId":"13184450879028133407"}},"outputId":"6171bdc4-9c50-4721-c6c5-6361bf72bec3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-887147e136c8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbase_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"llama2-7b-chat-hf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_path = os.path.join(local_model_folder,\n\u001b[0m\u001b[1;32m      3\u001b[0m                           base_model_name)\n\u001b[1;32m      4\u001b[0m base_model = LlamaForCausalLM.from_pretrained(model_path,\n\u001b[1;32m      5\u001b[0m                                               \u001b[0mload_in_8bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'local_model_folder' is not defined"]}]},{"cell_type":"code","source":["output = base_model.generate(**model_inputs, max_new_tokens=100, do_sample=True, top_p=0.9, temperature=0.05, num_beams=1)\n","resp = tokenizer.decode(output[0], skip_special_tokens=True).split('[/INST]')[1].strip()\n","\n","print(resp)"],"metadata":{"id":"iPkY9JipxL5Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load the adapter trained for capstone\n","\n","THe adapter partially works. The outputs is more concise than plain LLaMa2 but less concise than the paper."],"metadata":{"id":"SffUkSC2HWDj"}},{"cell_type":"code","source":["peft_model_id = 'BPO_models/capstone_peft_adapter'\n","capstone_adapter_path = os.path.join(local_model_folder,\n","                                     peft_model_id)\n","base_model.load_adapter(peft_model_id)"],"metadata":{"id":"Dcsm2hyt1Dln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output = base_model.generate(**model_inputs, max_new_tokens=1024, do_sample=True, top_p=0.9, temperature=0.05, num_beams=1)\n","resp = tokenizer.decode(output[0], skip_special_tokens=True).split('[/INST]')[1].strip()\n","\n","print(resp)"],"metadata":{"id":"n2b0MJM43j0D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xBg8uxeBeAjz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Stop execution"],"metadata":{"id":"hESBMGwIHlpK"}},{"cell_type":"code","source":["assert False"],"metadata":{"id":"ITuGcGtP4Kxx"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"73ce83ca131e4d63a17e92dab22ce4b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1f086f6816c4702a3a781427c68fde3","IPY_MODEL_0b94b81d4a2a4556ab7e6ebbeae001ea","IPY_MODEL_d16fd7abf5494cffba620cc665e1a5f5"],"layout":"IPY_MODEL_cd2b6d75c1da467d930f24925f393051"}},"f1f086f6816c4702a3a781427c68fde3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6febc3d5969403f8e2453e494c0f733","placeholder":"​","style":"IPY_MODEL_8a08515ef7a44e1a894ac4cd01cfc312","value":"Loading checkpoint shards: 100%"}},"0b94b81d4a2a4556ab7e6ebbeae001ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_801c94bee36544ca8d2e0d37553209d2","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_917c63ab4c1b4570805360e6b443b811","value":2}},"d16fd7abf5494cffba620cc665e1a5f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_880c31218c0e4f62a740f2821557b717","placeholder":"​","style":"IPY_MODEL_646853db92ad414eb268a61f57b1d373","value":" 2/2 [01:11&lt;00:00, 32.92s/it]"}},"cd2b6d75c1da467d930f24925f393051":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6febc3d5969403f8e2453e494c0f733":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a08515ef7a44e1a894ac4cd01cfc312":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"801c94bee36544ca8d2e0d37553209d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"917c63ab4c1b4570805360e6b443b811":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"880c31218c0e4f62a740f2821557b717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"646853db92ad414eb268a61f57b1d373":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}