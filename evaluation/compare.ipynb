{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read to the correct number in the dataset\n",
    "ds = load_dataset(\"gbharti/finance-alpaca\", cache_dir=\"../cache_dir\", split=f\"train[:24%]\")\n",
    "# If just generating for evaluation, look at eval set vs. gen set\n",
    "idxs = range(int(0.8) * len(ds), len(ds))\n",
    "ds = ds.select(idxs)\n",
    "ds = ds.map(\n",
    "    lambda example: {\"text\": \n",
    "                    f\"<s>[INST] {example['instruction']} [/INST]\"},\n",
    "    num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example(model, tokenizer, prompt, max_len):\n",
    "    tokens = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    prompt_len = tokens.input_ids.shape[1]\n",
    "    out = model.generate(**tokens, max_length=max_len, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.batch_decode(out[:,prompt_len:], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d5cf3e3ab74688b2b6949e769254a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_names = [\"mistralai/Mistral-7B-v0.1\", \"../results/sft-finqa/final_model\", \"../results/dpo-finqa/final_model\"]\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=\"float16\",\n",
    "        use_nested_quant = True,\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(model_names[0], \n",
    "                                             cache_dir=\"../cache_dir\", \n",
    "                                             device_map={\"\": 0}, \n",
    "                                             quantization_config=bnb_config)\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_names[0],\n",
    "                                          cache_dir=\"../cache_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [01:42<02:50, 34.05s/it]\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character '\\u2019' in position 170: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/home/danyoung/workspace/fin-rlhf/evaluation/compare.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfinstance-2.us-east1-d.accenture-capstone/home/danyoung/workspace/fin-rlhf/evaluation/compare.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m tqdm(ds[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m][:\u001b[39m8\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfinstance-2.us-east1-d.accenture-capstone/home/danyoung/workspace/fin-rlhf/evaluation/compare.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     response \u001b[39m=\u001b[39m generate_example(model, tokenizer, prompt, \u001b[39m1024\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfinstance-2.us-east1-d.accenture-capstone/home/danyoung/workspace/fin-rlhf/evaluation/compare.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     writer\u001b[39m.\u001b[39;49mwriterow({\u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt, \u001b[39m\"\u001b[39;49m\u001b[39mresponse\u001b[39;49m\u001b[39m\"\u001b[39;49m: response[\u001b[39m0\u001b[39;49m]})\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/csv.py:154\u001b[0m, in \u001b[0;36mDictWriter.writerow\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwriterow\u001b[39m(\u001b[39mself\u001b[39m, rowdict):\n\u001b[0;32m--> 154\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwriter\u001b[39m.\u001b[39;49mwriterow(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dict_to_list(rowdict))\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\u2019' in position 170: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "field_names = [\"prompt\", \"response\"]\n",
    "with open(\"base_generations.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.DictWriter(f, quoting=csv.QUOTE_MINIMAL, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    for prompt in tqdm(ds[\"text\"][:8]):\n",
    "        response = generate_example(model, tokenizer, prompt, 1024)\n",
    "        writer.writerow({\"prompt\": prompt, \"response\": response[0]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
